{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import google.generativeai as genai\n",
    "\n",
    "from articleCleaner import clean_all_articles\n",
    "from articleFetcher import fetchArticles\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "GOOGLE_GENAI_API_KEY = os.getenv(\"GOOGLE_GENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Configure the Google Generative AI library\n",
    "genai.configure(api_key=GOOGLE_GENAI_API_KEY)\n",
    "\n",
    "# Configure the Pinecone database\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch & Clean Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched articles from page 1\n",
      "Successfully fetched articles from page 2\n",
      "Successfully fetched articles from page 3\n",
      "300 articles successfully fetched\n"
     ]
    }
   ],
   "source": [
    "# Fetch articles\n",
    "STARTING_PAGE = 1\n",
    "ENDING_PAGE = 3\n",
    "articles = fetchArticles(starting_page=STARTING_PAGE, ending_page=ENDING_PAGE)\n",
    "\n",
    "if (articles != -1):\n",
    "    # Clean articles\n",
    "    print(len(articles), \"articles successfully fetched\")\n",
    "    clean_all_articles(articles)\n",
    "else:\n",
    "    print(\"Error fetching articles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Pinecone index (only run this once for one index)\n",
    "index_name = \"768dim\"\n",
    "\n",
    "# We still don't know what an index is :) maybe we won't ever know\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768, # Replace with your model dimensions\n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': [0.04913330078125, -0.01306915283203125, ..., -0.0196990966796875, -0.0110321044921875]}\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "embeddings = []\n",
    "for article in articles:\n",
    "    content = article['content']['rendered']\n",
    "    article_id = str(article['id'])\n",
    "    \n",
    "    if content and article_id:\n",
    "        try:\n",
    "            # Generate embedding using Google Gemini\n",
    "            embedding_response = genai.embed_content(\n",
    "                  model=\"models/text-embedding-004\",\n",
    "                  content=content)\n",
    "            embedding_vector = embedding_response['embedding']\n",
    "            print(embedding_vector)\n",
    "            \n",
    "            # Append to embeddings list\n",
    "            embeddings.append({\n",
    "                \"id\": article_id,\n",
    "                \"values\": embedding_vector,\n",
    "                \"metadata\": {\n",
    "                    \"date\": article['date'],\n",
    "                    \"date_gmt\": article['date_gmt'],\n",
    "                    \"link\": article['link']\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embedding for article {article_id}: {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping article with missing content or ID: {article}\")\n",
    "\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the index to be ready\n",
    "while not pc.describe_index(\"768dim\").status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(\"768dim\")\n",
    "\n",
    "index.upsert(\n",
    "    vectors=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me about the tech company known as Apple.\"\n",
    "\n",
    "embedding = pc.inference.embed(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    inputs=[query],\n",
    "    parameters={\n",
    "        \"input_type\": \"query\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = index.query(\n",
    "    namespace=\"ns1\",\n",
    "    vector=embedding[0].values,\n",
    "    top_k=3,\n",
    "    include_values=False,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
